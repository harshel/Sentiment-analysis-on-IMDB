{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the necessary libraries\n",
    "import torch\n",
    "import torchtext\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "\n",
    "import random\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the SEED for reproducebility\n",
    "SEED = 101\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create our TEXT field and the LABEL field, which will hold our actual TEXT and the LABELS correspondingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the Field and the Labels\n",
    "TEXT = data.Field(sequential = True, lower = True)\n",
    "LABEL = data.LabelField(dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now let's load our data\n",
    "#the following code will load our IMDB data and split it into training and testing set\n",
    "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<torchtext.data.example.Example at 0x269e44fa320>,\n",
       " <torchtext.data.example.Example at 0x269e44fa2b0>,\n",
       " <torchtext.data.example.Example at 0x269e44fa4a8>,\n",
       " <torchtext.data.example.Example at 0x269e44fa4e0>,\n",
       " <torchtext.data.example.Example at 0x269e44fa518>,\n",
       " <torchtext.data.example.Example at 0x269e44fa550>,\n",
       " <torchtext.data.example.Example at 0x269e44fa588>,\n",
       " <torchtext.data.example.Example at 0x269e44fa5c0>,\n",
       " <torchtext.data.example.Example at 0x269e44fa5f8>,\n",
       " <torchtext.data.example.Example at 0x269e44fa630>,\n",
       " <torchtext.data.example.Example at 0x269e44fa668>,\n",
       " <torchtext.data.example.Example at 0x269e44fa6a0>,\n",
       " <torchtext.data.example.Example at 0x269e44fa6d8>,\n",
       " <torchtext.data.example.Example at 0x269e44fa710>,\n",
       " <torchtext.data.example.Example at 0x269e44fa748>,\n",
       " <torchtext.data.example.Example at 0x269e44fa780>,\n",
       " <torchtext.data.example.Example at 0x269e44fa7b8>,\n",
       " <torchtext.data.example.Example at 0x269e44fa7f0>,\n",
       " <torchtext.data.example.Example at 0x269e44fa828>,\n",
       " <torchtext.data.example.Example at 0x269e44fa860>,\n",
       " <torchtext.data.example.Example at 0x269e44fa898>,\n",
       " <torchtext.data.example.Example at 0x269e44fa8d0>,\n",
       " <torchtext.data.example.Example at 0x269e44fa908>,\n",
       " <torchtext.data.example.Example at 0x269e44fa940>,\n",
       " <torchtext.data.example.Example at 0x269e44fa978>,\n",
       " <torchtext.data.example.Example at 0x269e44fa9b0>,\n",
       " <torchtext.data.example.Example at 0x269e44fa9e8>,\n",
       " <torchtext.data.example.Example at 0x269e44faa20>,\n",
       " <torchtext.data.example.Example at 0x269e44faa58>,\n",
       " <torchtext.data.example.Example at 0x269e44faa90>,\n",
       " <torchtext.data.example.Example at 0x269e44faac8>,\n",
       " <torchtext.data.example.Example at 0x269e44fab00>,\n",
       " <torchtext.data.example.Example at 0x269e44fab38>,\n",
       " <torchtext.data.example.Example at 0x269e44fab70>,\n",
       " <torchtext.data.example.Example at 0x269e44faba8>,\n",
       " <torchtext.data.example.Example at 0x269e44fabe0>,\n",
       " <torchtext.data.example.Example at 0x269e44fac18>,\n",
       " <torchtext.data.example.Example at 0x269e44fac50>,\n",
       " <torchtext.data.example.Example at 0x269e44fac88>,\n",
       " <torchtext.data.example.Example at 0x269e44facc0>,\n",
       " <torchtext.data.example.Example at 0x269e44facf8>,\n",
       " <torchtext.data.example.Example at 0x269e44fad30>,\n",
       " <torchtext.data.example.Example at 0x269e44fad68>,\n",
       " <torchtext.data.example.Example at 0x269e44fada0>,\n",
       " <torchtext.data.example.Example at 0x269e44fadd8>,\n",
       " <torchtext.data.example.Example at 0x269e44fae10>,\n",
       " <torchtext.data.example.Example at 0x269e44fae48>,\n",
       " <torchtext.data.example.Example at 0x269e44fae80>,\n",
       " <torchtext.data.example.Example at 0x269e44faeb8>,\n",
       " <torchtext.data.example.Example at 0x269e44faef0>,\n",
       " <torchtext.data.example.Example at 0x269e44faf28>,\n",
       " <torchtext.data.example.Example at 0x269e44faf60>,\n",
       " <torchtext.data.example.Example at 0x269e44faf98>,\n",
       " <torchtext.data.example.Example at 0x269e44fafd0>,\n",
       " <torchtext.data.example.Example at 0x269e44fa2e8>,\n",
       " <torchtext.data.example.Example at 0x269e44fa470>,\n",
       " <torchtext.data.example.Example at 0x269e44fa400>,\n",
       " <torchtext.data.example.Example at 0x269e44fa438>,\n",
       " <torchtext.data.example.Example at 0x269e44fa358>,\n",
       " <torchtext.data.example.Example at 0x269e44fa390>,\n",
       " <torchtext.data.example.Example at 0x269e44fa3c8>,\n",
       " <torchtext.data.example.Example at 0x269e55a11d0>,\n",
       " <torchtext.data.example.Example at 0x269e55a1208>,\n",
       " <torchtext.data.example.Example at 0x269e55a1240>,\n",
       " <torchtext.data.example.Example at 0x269e55a1278>,\n",
       " <torchtext.data.example.Example at 0x269e55a12b0>,\n",
       " <torchtext.data.example.Example at 0x269e55a12e8>,\n",
       " <torchtext.data.example.Example at 0x269e55a1320>,\n",
       " <torchtext.data.example.Example at 0x269e55a1358>,\n",
       " <torchtext.data.example.Example at 0x269e55a1390>,\n",
       " <torchtext.data.example.Example at 0x269e55a13c8>,\n",
       " <torchtext.data.example.Example at 0x269e55a1400>,\n",
       " <torchtext.data.example.Example at 0x269e55a1438>,\n",
       " <torchtext.data.example.Example at 0x269e55a1470>,\n",
       " <torchtext.data.example.Example at 0x269e55a14e0>,\n",
       " <torchtext.data.example.Example at 0x269e55a1518>,\n",
       " <torchtext.data.example.Example at 0x269e55a1048>,\n",
       " <torchtext.data.example.Example at 0x269e55a1160>,\n",
       " <torchtext.data.example.Example at 0x269e55a10f0>,\n",
       " <torchtext.data.example.Example at 0x269e55a1128>,\n",
       " <torchtext.data.example.Example at 0x269e55a1198>,\n",
       " <torchtext.data.example.Example at 0x269e55a10b8>,\n",
       " <torchtext.data.example.Example at 0x269e55a1080>,\n",
       " <torchtext.data.example.Example at 0x269e55f9278>,\n",
       " <torchtext.data.example.Example at 0x269e55f92b0>,\n",
       " <torchtext.data.example.Example at 0x269e55f92e8>,\n",
       " <torchtext.data.example.Example at 0x269e55f9320>,\n",
       " <torchtext.data.example.Example at 0x269e55f9358>,\n",
       " <torchtext.data.example.Example at 0x269e55f9390>,\n",
       " <torchtext.data.example.Example at 0x269e55f93c8>,\n",
       " <torchtext.data.example.Example at 0x269e55f9438>,\n",
       " <torchtext.data.example.Example at 0x269e55f9470>,\n",
       " <torchtext.data.example.Example at 0x269e55f9208>,\n",
       " <torchtext.data.example.Example at 0x269e55f9160>,\n",
       " <torchtext.data.example.Example at 0x269e55f90f0>,\n",
       " <torchtext.data.example.Example at 0x269e55f9240>,\n",
       " <torchtext.data.example.Example at 0x269e55f9198>,\n",
       " <torchtext.data.example.Example at 0x269e55f9128>,\n",
       " <torchtext.data.example.Example at 0x269e55f91d0>,\n",
       " <torchtext.data.example.Example at 0x269e5600668>,\n",
       " <torchtext.data.example.Example at 0x269e56006a0>,\n",
       " <torchtext.data.example.Example at 0x269e56006d8>,\n",
       " <torchtext.data.example.Example at 0x269e5600710>,\n",
       " <torchtext.data.example.Example at 0x269e5600748>,\n",
       " <torchtext.data.example.Example at 0x269e5600780>,\n",
       " <torchtext.data.example.Example at 0x269e56007f0>,\n",
       " <torchtext.data.example.Example at 0x269e5600828>,\n",
       " <torchtext.data.example.Example at 0x269e563ad68>,\n",
       " <torchtext.data.example.Example at 0x269e563ada0>,\n",
       " <torchtext.data.example.Example at 0x269e569d898>,\n",
       " <torchtext.data.example.Example at 0x269e569d908>,\n",
       " <torchtext.data.example.Example at 0x269e56aca20>,\n",
       " <torchtext.data.example.Example at 0x269e56aca58>,\n",
       " <torchtext.data.example.Example at 0x269e5600588>,\n",
       " <torchtext.data.example.Example at 0x269e56ad7b8>,\n",
       " <torchtext.data.example.Example at 0x269e56ad7f0>,\n",
       " <torchtext.data.example.Example at 0x269e5600550>,\n",
       " <torchtext.data.example.Example at 0x269e56005f8>,\n",
       " <torchtext.data.example.Example at 0x269e56ad748>,\n",
       " <torchtext.data.example.Example at 0x269e5600518>,\n",
       " <torchtext.data.example.Example at 0x269e56004e0>,\n",
       " <torchtext.data.example.Example at 0x269e56005c0>,\n",
       " <torchtext.data.example.Example at 0x269e5600630>,\n",
       " <torchtext.data.example.Example at 0x269e56b2c88>,\n",
       " <torchtext.data.example.Example at 0x269e56b2cc0>,\n",
       " <torchtext.data.example.Example at 0x269e56b2cf8>,\n",
       " <torchtext.data.example.Example at 0x269e56b2d30>,\n",
       " <torchtext.data.example.Example at 0x269e56b2da0>,\n",
       " <torchtext.data.example.Example at 0x269e56b2dd8>,\n",
       " <torchtext.data.example.Example at 0x269e56b2c50>,\n",
       " <torchtext.data.example.Example at 0x269e56b54a8>,\n",
       " <torchtext.data.example.Example at 0x269e56b54e0>,\n",
       " <torchtext.data.example.Example at 0x269e56b2c18>,\n",
       " <torchtext.data.example.Example at 0x269e56b2b00>,\n",
       " <torchtext.data.example.Example at 0x269e56b5438>,\n",
       " <torchtext.data.example.Example at 0x269e56b2b70>,\n",
       " <torchtext.data.example.Example at 0x269e56b2ba8>,\n",
       " <torchtext.data.example.Example at 0x269e56d8f60>,\n",
       " <torchtext.data.example.Example at 0x269e56d8fd0>,\n",
       " <torchtext.data.example.Example at 0x269e56db048>,\n",
       " <torchtext.data.example.Example at 0x269e56d8f28>,\n",
       " <torchtext.data.example.Example at 0x269e56b2be0>,\n",
       " <torchtext.data.example.Example at 0x269e56b2b38>,\n",
       " <torchtext.data.example.Example at 0x269e56d8ef0>,\n",
       " <torchtext.data.example.Example at 0x269e56d8438>,\n",
       " <torchtext.data.example.Example at 0x269e56d8400>,\n",
       " <torchtext.data.example.Example at 0x269e56d8eb8>,\n",
       " <torchtext.data.example.Example at 0x269e56e6208>,\n",
       " <torchtext.data.example.Example at 0x269e56e6240>,\n",
       " <torchtext.data.example.Example at 0x269e56edda0>,\n",
       " <torchtext.data.example.Example at 0x269e56ede10>,\n",
       " <torchtext.data.example.Example at 0x269e56f19b0>,\n",
       " <torchtext.data.example.Example at 0x269e56f19e8>,\n",
       " <torchtext.data.example.Example at 0x269e56e6198>,\n",
       " <torchtext.data.example.Example at 0x269e56e60f0>,\n",
       " <torchtext.data.example.Example at 0x269e56e6128>,\n",
       " <torchtext.data.example.Example at 0x269e56e60b8>,\n",
       " <torchtext.data.example.Example at 0x269e56e6080>,\n",
       " <torchtext.data.example.Example at 0x269e56e6048>,\n",
       " <torchtext.data.example.Example at 0x269e56e6160>,\n",
       " <torchtext.data.example.Example at 0x269e56ffdd8>,\n",
       " <torchtext.data.example.Example at 0x269e56ffe10>,\n",
       " <torchtext.data.example.Example at 0x269e56ffe48>,\n",
       " <torchtext.data.example.Example at 0x269e56ffe80>,\n",
       " <torchtext.data.example.Example at 0x269e56ffeb8>,\n",
       " <torchtext.data.example.Example at 0x269e56ffef0>,\n",
       " <torchtext.data.example.Example at 0x269e56fff28>,\n",
       " <torchtext.data.example.Example at 0x269e56fff60>,\n",
       " <torchtext.data.example.Example at 0x269e56fff98>,\n",
       " <torchtext.data.example.Example at 0x269e56fffd0>,\n",
       " <torchtext.data.example.Example at 0x269e56ffcc0>,\n",
       " <torchtext.data.example.Example at 0x269e56ffc88>,\n",
       " <torchtext.data.example.Example at 0x269e56ffd68>,\n",
       " <torchtext.data.example.Example at 0x269e56ffcf8>,\n",
       " <torchtext.data.example.Example at 0x269e56ffc50>,\n",
       " <torchtext.data.example.Example at 0x269e56ffd30>,\n",
       " <torchtext.data.example.Example at 0x269e56ffda0>,\n",
       " <torchtext.data.example.Example at 0x269e57011d0>,\n",
       " <torchtext.data.example.Example at 0x269e5701208>,\n",
       " <torchtext.data.example.Example at 0x269e5701240>,\n",
       " <torchtext.data.example.Example at 0x269e5701278>,\n",
       " <torchtext.data.example.Example at 0x269e57012b0>,\n",
       " <torchtext.data.example.Example at 0x269e57012e8>,\n",
       " <torchtext.data.example.Example at 0x269e5701320>,\n",
       " <torchtext.data.example.Example at 0x269e5701390>,\n",
       " <torchtext.data.example.Example at 0x269e57013c8>,\n",
       " <torchtext.data.example.Example at 0x269e57030b8>,\n",
       " <torchtext.data.example.Example at 0x269e57030f0>,\n",
       " <torchtext.data.example.Example at 0x269e5701080>,\n",
       " <torchtext.data.example.Example at 0x269e5701128>,\n",
       " <torchtext.data.example.Example at 0x269e57010b8>,\n",
       " <torchtext.data.example.Example at 0x269e5704278>,\n",
       " <torchtext.data.example.Example at 0x269e5701160>,\n",
       " <torchtext.data.example.Example at 0x269e57010f0>,\n",
       " <torchtext.data.example.Example at 0x269e5704198>,\n",
       " <torchtext.data.example.Example at 0x269e5717ac8>,\n",
       " <torchtext.data.example.Example at 0x269e5701198>,\n",
       " <torchtext.data.example.Example at 0x269e5730278>,\n",
       " <torchtext.data.example.Example at 0x269e5717a58>,\n",
       " <torchtext.data.example.Example at 0x269e57041d0>,\n",
       " <torchtext.data.example.Example at 0x269e5701048>,\n",
       " <torchtext.data.example.Example at 0x269e57042b0>,\n",
       " <torchtext.data.example.Example at 0x269e5704208>,\n",
       " <torchtext.data.example.Example at 0x269e5717b00>,\n",
       " <torchtext.data.example.Example at 0x269e5717a20>,\n",
       " <torchtext.data.example.Example at 0x269e57446d8>,\n",
       " <torchtext.data.example.Example at 0x269e5744710>,\n",
       " <torchtext.data.example.Example at 0x269e5744748>,\n",
       " <torchtext.data.example.Example at 0x269e5744780>,\n",
       " <torchtext.data.example.Example at 0x269e57447b8>,\n",
       " <torchtext.data.example.Example at 0x269e57447f0>,\n",
       " <torchtext.data.example.Example at 0x269e5744828>,\n",
       " <torchtext.data.example.Example at 0x269e5744860>,\n",
       " <torchtext.data.example.Example at 0x269e5744898>,\n",
       " <torchtext.data.example.Example at 0x269e5744908>,\n",
       " <torchtext.data.example.Example at 0x269e5744940>,\n",
       " <torchtext.data.example.Example at 0x269e5744588>,\n",
       " <torchtext.data.example.Example at 0x269e5744630>,\n",
       " <torchtext.data.example.Example at 0x269e57445c0>,\n",
       " <torchtext.data.example.Example at 0x269e5744550>,\n",
       " <torchtext.data.example.Example at 0x269e5744668>,\n",
       " <torchtext.data.example.Example at 0x269e57446a0>,\n",
       " <torchtext.data.example.Example at 0x269e57445f8>,\n",
       " <torchtext.data.example.Example at 0x269e57557b8>,\n",
       " <torchtext.data.example.Example at 0x269e57557f0>,\n",
       " <torchtext.data.example.Example at 0x269e5755860>,\n",
       " <torchtext.data.example.Example at 0x269e5755898>,\n",
       " <torchtext.data.example.Example at 0x269e5755668>,\n",
       " <torchtext.data.example.Example at 0x269e5755710>,\n",
       " <torchtext.data.example.Example at 0x269e57556a0>,\n",
       " <torchtext.data.example.Example at 0x269e5755630>,\n",
       " <torchtext.data.example.Example at 0x269e5755748>,\n",
       " <torchtext.data.example.Example at 0x269e5755780>,\n",
       " <torchtext.data.example.Example at 0x269e57556d8>,\n",
       " <torchtext.data.example.Example at 0x269e5792588>,\n",
       " <torchtext.data.example.Example at 0x269e57925f8>,\n",
       " <torchtext.data.example.Example at 0x269e57924e0>,\n",
       " <torchtext.data.example.Example at 0x269e5792438>,\n",
       " <torchtext.data.example.Example at 0x269e57923c8>,\n",
       " <torchtext.data.example.Example at 0x269e5792518>,\n",
       " <torchtext.data.example.Example at 0x269e5792470>,\n",
       " <torchtext.data.example.Example at 0x269e5792400>,\n",
       " <torchtext.data.example.Example at 0x269e57f5f98>,\n",
       " <torchtext.data.example.Example at 0x269e57f5fd0>,\n",
       " <torchtext.data.example.Example at 0x269e57f5f28>,\n",
       " <torchtext.data.example.Example at 0x269e57f60f0>,\n",
       " <torchtext.data.example.Example at 0x269e57f6128>,\n",
       " <torchtext.data.example.Example at 0x269e57f5ef0>,\n",
       " <torchtext.data.example.Example at 0x269e569d8d0>,\n",
       " <torchtext.data.example.Example at 0x269e569de80>,\n",
       " <torchtext.data.example.Example at 0x269e568d358>,\n",
       " <torchtext.data.example.Example at 0x269e5648518>,\n",
       " <torchtext.data.example.Example at 0x269e58027b8>,\n",
       " <torchtext.data.example.Example at 0x269e57f6048>,\n",
       " <torchtext.data.example.Example at 0x269e57f5f60>,\n",
       " <torchtext.data.example.Example at 0x269e57924a8>,\n",
       " <torchtext.data.example.Example at 0x269e569d940>,\n",
       " <torchtext.data.example.Example at 0x269e57f5e80>,\n",
       " <torchtext.data.example.Example at 0x269e57f5eb8>,\n",
       " <torchtext.data.example.Example at 0x269e57f5e48>,\n",
       " <torchtext.data.example.Example at 0x269e581d710>,\n",
       " <torchtext.data.example.Example at 0x269e581d748>,\n",
       " <torchtext.data.example.Example at 0x269e581d780>,\n",
       " <torchtext.data.example.Example at 0x269e581d7b8>,\n",
       " <torchtext.data.example.Example at 0x269e581d7f0>,\n",
       " <torchtext.data.example.Example at 0x269e581d828>,\n",
       " <torchtext.data.example.Example at 0x269e581d898>,\n",
       " <torchtext.data.example.Example at 0x269e581d8d0>,\n",
       " <torchtext.data.example.Example at 0x269e581d588>,\n",
       " <torchtext.data.example.Example at 0x269e581d6a0>,\n",
       " <torchtext.data.example.Example at 0x269e58a7f98>,\n",
       " <torchtext.data.example.Example at 0x269e581d668>,\n",
       " <torchtext.data.example.Example at 0x269e581d5f8>,\n",
       " <torchtext.data.example.Example at 0x269e58a7f60>,\n",
       " <torchtext.data.example.Example at 0x269e581d5c0>,\n",
       " <torchtext.data.example.Example at 0x269e58aa128>,\n",
       " <torchtext.data.example.Example at 0x269e58a7f28>,\n",
       " <torchtext.data.example.Example at 0x269e581d6d8>,\n",
       " <torchtext.data.example.Example at 0x269e58aa048>,\n",
       " <torchtext.data.example.Example at 0x269e58a7fd0>,\n",
       " <torchtext.data.example.Example at 0x269e581d630>,\n",
       " <torchtext.data.example.Example at 0x269e58aa080>,\n",
       " <torchtext.data.example.Example at 0x269e58aa160>,\n",
       " <torchtext.data.example.Example at 0x269e58aa0b8>,\n",
       " <torchtext.data.example.Example at 0x269e58ac828>,\n",
       " <torchtext.data.example.Example at 0x269e58ac860>,\n",
       " <torchtext.data.example.Example at 0x269e58ac898>,\n",
       " <torchtext.data.example.Example at 0x269e58ac8d0>,\n",
       " <torchtext.data.example.Example at 0x269e58ac908>,\n",
       " <torchtext.data.example.Example at 0x269e58ac940>,\n",
       " <torchtext.data.example.Example at 0x269e58ac978>,\n",
       " <torchtext.data.example.Example at 0x269e58ac9b0>,\n",
       " <torchtext.data.example.Example at 0x269e58ac9e8>,\n",
       " <torchtext.data.example.Example at 0x269e58aca20>,\n",
       " <torchtext.data.example.Example at 0x269e58aca58>,\n",
       " <torchtext.data.example.Example at 0x269e58aca90>,\n",
       " <torchtext.data.example.Example at 0x269e58acac8>,\n",
       " <torchtext.data.example.Example at 0x269e58acb00>,\n",
       " <torchtext.data.example.Example at 0x269e58acb38>,\n",
       " <torchtext.data.example.Example at 0x269e58acba8>,\n",
       " <torchtext.data.example.Example at 0x269e58acbe0>,\n",
       " <torchtext.data.example.Example at 0x269e58ac710>,\n",
       " <torchtext.data.example.Example at 0x269e58ac6d8>,\n",
       " <torchtext.data.example.Example at 0x269e58ac7b8>,\n",
       " <torchtext.data.example.Example at 0x269e58ac748>,\n",
       " <torchtext.data.example.Example at 0x269e58ac6a0>,\n",
       " <torchtext.data.example.Example at 0x269e58ac780>,\n",
       " <torchtext.data.example.Example at 0x269e58afcf8>,\n",
       " <torchtext.data.example.Example at 0x269e58afda0>,\n",
       " <torchtext.data.example.Example at 0x269e58ae6a0>,\n",
       " <torchtext.data.example.Example at 0x269e58afcc0>,\n",
       " <torchtext.data.example.Example at 0x269e58afc18>,\n",
       " <torchtext.data.example.Example at 0x269e58ac7f0>,\n",
       " <torchtext.data.example.Example at 0x269e58afbe0>,\n",
       " <torchtext.data.example.Example at 0x269e58afba8>,\n",
       " <torchtext.data.example.Example at 0x269e58afc50>,\n",
       " <torchtext.data.example.Example at 0x269e58afc88>,\n",
       " <torchtext.data.example.Example at 0x269e58c67f0>,\n",
       " <torchtext.data.example.Example at 0x269e58c6828>,\n",
       " <torchtext.data.example.Example at 0x269e58c6748>,\n",
       " <torchtext.data.example.Example at 0x269e58c66a0>,\n",
       " <torchtext.data.example.Example at 0x269e58c6630>,\n",
       " <torchtext.data.example.Example at 0x269e58c6780>,\n",
       " <torchtext.data.example.Example at 0x269e58c66d8>,\n",
       " <torchtext.data.example.Example at 0x269e58c6668>,\n",
       " <torchtext.data.example.Example at 0x269e58efc18>,\n",
       " <torchtext.data.example.Example at 0x269e58efc50>,\n",
       " <torchtext.data.example.Example at 0x269e58efb70>,\n",
       " <torchtext.data.example.Example at 0x269e58efba8>,\n",
       " <torchtext.data.example.Example at 0x269e5971908>,\n",
       " <torchtext.data.example.Example at 0x269e58efa90>,\n",
       " <torchtext.data.example.Example at 0x269e58c6710>,\n",
       " <torchtext.data.example.Example at 0x269e5971898>,\n",
       " <torchtext.data.example.Example at 0x269e58efb38>,\n",
       " <torchtext.data.example.Example at 0x269e5971940>,\n",
       " <torchtext.data.example.Example at 0x269e5971860>,\n",
       " <torchtext.data.example.Example at 0x269e58efac8>,\n",
       " <torchtext.data.example.Example at 0x269e58efb00>,\n",
       " <torchtext.data.example.Example at 0x269e5998ef0>,\n",
       " <torchtext.data.example.Example at 0x269e5998f28>,\n",
       " <torchtext.data.example.Example at 0x269e5998f60>,\n",
       " <torchtext.data.example.Example at 0x269e5998f98>,\n",
       " <torchtext.data.example.Example at 0x269e5998fd0>,\n",
       " <torchtext.data.example.Example at 0x269e5998e48>,\n",
       " <torchtext.data.example.Example at 0x269e5998eb8>,\n",
       " <torchtext.data.example.Example at 0x269e5998da0>,\n",
       " <torchtext.data.example.Example at 0x269e5998e80>,\n",
       " <torchtext.data.example.Example at 0x269e5998dd8>,\n",
       " <torchtext.data.example.Example at 0x269e5998e10>,\n",
       " <torchtext.data.example.Example at 0x269e599e1d0>,\n",
       " <torchtext.data.example.Example at 0x269e599e208>,\n",
       " <torchtext.data.example.Example at 0x269e599e128>,\n",
       " <torchtext.data.example.Example at 0x269e599e160>,\n",
       " <torchtext.data.example.Example at 0x269e5998d68>,\n",
       " <torchtext.data.example.Example at 0x269e599e048>,\n",
       " <torchtext.data.example.Example at 0x269e599e080>,\n",
       " <torchtext.data.example.Example at 0x269e599e0b8>,\n",
       " <torchtext.data.example.Example at 0x269e599e0f0>,\n",
       " <torchtext.data.example.Example at 0x269e59a7d68>,\n",
       " <torchtext.data.example.Example at 0x269e59a7dd8>,\n",
       " <torchtext.data.example.Example at 0x269e59a7e10>,\n",
       " <torchtext.data.example.Example at 0x269e59a7c50>,\n",
       " <torchtext.data.example.Example at 0x269e59a7c18>,\n",
       " <torchtext.data.example.Example at 0x269e59a7cf8>,\n",
       " <torchtext.data.example.Example at 0x269e59a7c88>,\n",
       " <torchtext.data.example.Example at 0x269e59a7be0>,\n",
       " <torchtext.data.example.Example at 0x269e59a7cc0>,\n",
       " <torchtext.data.example.Example at 0x269e59b5898>,\n",
       " <torchtext.data.example.Example at 0x269e59b58d0>,\n",
       " <torchtext.data.example.Example at 0x269e59b57f0>,\n",
       " <torchtext.data.example.Example at 0x269e59b5828>,\n",
       " <torchtext.data.example.Example at 0x269e59c1c50>,\n",
       " <torchtext.data.example.Example at 0x269e59b5710>,\n",
       " <torchtext.data.example.Example at 0x269e59e39b0>,\n",
       " <torchtext.data.example.Example at 0x269e59e39e8>,\n",
       " <torchtext.data.example.Example at 0x269e59b5748>,\n",
       " <torchtext.data.example.Example at 0x269e59c1c88>,\n",
       " <torchtext.data.example.Example at 0x269e59a7d30>,\n",
       " <torchtext.data.example.Example at 0x269e59eb550>,\n",
       " <torchtext.data.example.Example at 0x269e59c1ba8>,\n",
       " <torchtext.data.example.Example at 0x269e59f7898>,\n",
       " <torchtext.data.example.Example at 0x269e59eb4a8>,\n",
       " <torchtext.data.example.Example at 0x269e59c1be0>,\n",
       " <torchtext.data.example.Example at 0x269e59eb518>,\n",
       " <torchtext.data.example.Example at 0x269e59eb4e0>,\n",
       " <torchtext.data.example.Example at 0x269e5a00a90>,\n",
       " <torchtext.data.example.Example at 0x269e59b57b8>,\n",
       " <torchtext.data.example.Example at 0x269e59b5780>,\n",
       " <torchtext.data.example.Example at 0x269e5a009b0>,\n",
       " <torchtext.data.example.Example at 0x269e5a00ac8>,\n",
       " <torchtext.data.example.Example at 0x269e5a11f98>,\n",
       " <torchtext.data.example.Example at 0x269e5a009e8>,\n",
       " <torchtext.data.example.Example at 0x269e5a00a20>,\n",
       " <torchtext.data.example.Example at 0x269e5a11ef0>,\n",
       " <torchtext.data.example.Example at 0x269e59eb5f8>,\n",
       " <torchtext.data.example.Example at 0x269e5a00978>,\n",
       " <torchtext.data.example.Example at 0x269e5a11f28>,\n",
       " <torchtext.data.example.Example at 0x269e5a11fd0>,\n",
       " <torchtext.data.example.Example at 0x269e5a11f60>,\n",
       " <torchtext.data.example.Example at 0x269e5a121d0>,\n",
       " <torchtext.data.example.Example at 0x269e5a12208>,\n",
       " <torchtext.data.example.Example at 0x269e5a12240>,\n",
       " <torchtext.data.example.Example at 0x269e5a12278>,\n",
       " <torchtext.data.example.Example at 0x269e5a122b0>,\n",
       " <torchtext.data.example.Example at 0x269e5a122e8>,\n",
       " <torchtext.data.example.Example at 0x269e5a12320>,\n",
       " <torchtext.data.example.Example at 0x269e5a12358>,\n",
       " <torchtext.data.example.Example at 0x269e5a12390>,\n",
       " <torchtext.data.example.Example at 0x269e5a123c8>,\n",
       " <torchtext.data.example.Example at 0x269e5a12400>,\n",
       " <torchtext.data.example.Example at 0x269e5a12438>,\n",
       " <torchtext.data.example.Example at 0x269e5a124a8>,\n",
       " <torchtext.data.example.Example at 0x269e5a124e0>,\n",
       " <torchtext.data.example.Example at 0x269e5a120f0>,\n",
       " <torchtext.data.example.Example at 0x269e5a19da0>,\n",
       " <torchtext.data.example.Example at 0x269e5a19dd8>,\n",
       " <torchtext.data.example.Example at 0x269e5a120b8>,\n",
       " <torchtext.data.example.Example at 0x269e5a8a0b8>,\n",
       " <torchtext.data.example.Example at 0x269e5a8a0f0>,\n",
       " <torchtext.data.example.Example at 0x269e5a82a20>,\n",
       " <torchtext.data.example.Example at 0x269e5a82a58>,\n",
       " <torchtext.data.example.Example at 0x269e5a12048>,\n",
       " <torchtext.data.example.Example at 0x269e5a19d30>,\n",
       " <torchtext.data.example.Example at 0x269e5a12128>,\n",
       " <torchtext.data.example.Example at 0x269e5a12080>,\n",
       " <torchtext.data.example.Example at 0x269e5a8a048>,\n",
       " <torchtext.data.example.Example at 0x269e5a12198>,\n",
       " <torchtext.data.example.Example at 0x269e5a12160>,\n",
       " <torchtext.data.example.Example at 0x269e5a87208>,\n",
       " <torchtext.data.example.Example at 0x269e5a87240>,\n",
       " <torchtext.data.example.Example at 0x269e5a87278>,\n",
       " <torchtext.data.example.Example at 0x269e5a872b0>,\n",
       " <torchtext.data.example.Example at 0x269e5a872e8>,\n",
       " <torchtext.data.example.Example at 0x269e5a87320>,\n",
       " <torchtext.data.example.Example at 0x269e5a87358>,\n",
       " <torchtext.data.example.Example at 0x269e5a87390>,\n",
       " <torchtext.data.example.Example at 0x269e5a873c8>,\n",
       " <torchtext.data.example.Example at 0x269e5a87400>,\n",
       " <torchtext.data.example.Example at 0x269e5a87438>,\n",
       " <torchtext.data.example.Example at 0x269e5a87470>,\n",
       " <torchtext.data.example.Example at 0x269e5a874a8>,\n",
       " <torchtext.data.example.Example at 0x269e5a874e0>,\n",
       " <torchtext.data.example.Example at 0x269e5a87518>,\n",
       " <torchtext.data.example.Example at 0x269e5a87550>,\n",
       " <torchtext.data.example.Example at 0x269e5a87588>,\n",
       " <torchtext.data.example.Example at 0x269e5a875c0>,\n",
       " <torchtext.data.example.Example at 0x269e5a875f8>,\n",
       " <torchtext.data.example.Example at 0x269e5a87630>,\n",
       " <torchtext.data.example.Example at 0x269e5a87668>,\n",
       " <torchtext.data.example.Example at 0x269e5a876a0>,\n",
       " <torchtext.data.example.Example at 0x269e5a876d8>,\n",
       " <torchtext.data.example.Example at 0x269e5a87710>,\n",
       " <torchtext.data.example.Example at 0x269e5a87748>,\n",
       " <torchtext.data.example.Example at 0x269e5a87780>,\n",
       " <torchtext.data.example.Example at 0x269e5a877b8>,\n",
       " <torchtext.data.example.Example at 0x269e5a877f0>,\n",
       " <torchtext.data.example.Example at 0x269e5a87828>,\n",
       " <torchtext.data.example.Example at 0x269e5a87860>,\n",
       " <torchtext.data.example.Example at 0x269e5a87898>,\n",
       " <torchtext.data.example.Example at 0x269e5a878d0>,\n",
       " <torchtext.data.example.Example at 0x269e5a87908>,\n",
       " <torchtext.data.example.Example at 0x269e5a87940>,\n",
       " <torchtext.data.example.Example at 0x269e5a879e8>,\n",
       " <torchtext.data.example.Example at 0x269e5acfbe0>,\n",
       " <torchtext.data.example.Example at 0x269e5a87080>,\n",
       " <torchtext.data.example.Example at 0x269e5b40f98>,\n",
       " <torchtext.data.example.Example at 0x269e5b40fd0>,\n",
       " <torchtext.data.example.Example at 0x269e5a870b8>,\n",
       " <torchtext.data.example.Example at 0x269e5a870f0>,\n",
       " <torchtext.data.example.Example at 0x269e5b40f60>,\n",
       " <torchtext.data.example.Example at 0x269e5a87160>,\n",
       " <torchtext.data.example.Example at 0x269e5a87198>,\n",
       " <torchtext.data.example.Example at 0x269e5b41198>,\n",
       " <torchtext.data.example.Example at 0x269e5b411d0>,\n",
       " <torchtext.data.example.Example at 0x269e5b53be0>,\n",
       " <torchtext.data.example.Example at 0x269e5b53c18>,\n",
       " <torchtext.data.example.Example at 0x269e5b41080>,\n",
       " <torchtext.data.example.Example at 0x269e5b41048>,\n",
       " <torchtext.data.example.Example at 0x269e5b554a8>,\n",
       " <torchtext.data.example.Example at 0x269e5b410b8>,\n",
       " <torchtext.data.example.Example at 0x269e5a87128>,\n",
       " <torchtext.data.example.Example at 0x269e5b55438>,\n",
       " <torchtext.data.example.Example at 0x269e5b80f60>,\n",
       " <torchtext.data.example.Example at 0x269e5a871d0>,\n",
       " <torchtext.data.example.Example at 0x269e5b410f0>,\n",
       " <torchtext.data.example.Example at 0x269e5b80ef0>,\n",
       " <torchtext.data.example.Example at 0x269e5b84cf8>,\n",
       " <torchtext.data.example.Example at 0x269e5b41128>,\n",
       " <torchtext.data.example.Example at 0x269e5b55400>,\n",
       " <torchtext.data.example.Example at 0x269e5b84c88>,\n",
       " <torchtext.data.example.Example at 0x269e5b80f98>,\n",
       " <torchtext.data.example.Example at 0x269e5b554e0>,\n",
       " <torchtext.data.example.Example at 0x269e5b84c50>,\n",
       " <torchtext.data.example.Example at 0x269e5b80eb8>,\n",
       " <torchtext.data.example.Example at 0x269e5b84d30>,\n",
       " <torchtext.data.example.Example at 0x269e5b87b38>,\n",
       " <torchtext.data.example.Example at 0x269e5b87b70>,\n",
       " <torchtext.data.example.Example at 0x269e5b87ba8>,\n",
       " <torchtext.data.example.Example at 0x269e5b87be0>,\n",
       " <torchtext.data.example.Example at 0x269e5b87c18>,\n",
       " <torchtext.data.example.Example at 0x269e5b87c50>,\n",
       " <torchtext.data.example.Example at 0x269e5b87c88>,\n",
       " <torchtext.data.example.Example at 0x269e5b87cc0>,\n",
       " <torchtext.data.example.Example at 0x269e5b87cf8>,\n",
       " <torchtext.data.example.Example at 0x269e5b87d68>,\n",
       " <torchtext.data.example.Example at 0x269e5b87da0>,\n",
       " <torchtext.data.example.Example at 0x269e5b879e8>,\n",
       " <torchtext.data.example.Example at 0x269e5b87a90>,\n",
       " <torchtext.data.example.Example at 0x269e5b87a20>,\n",
       " <torchtext.data.example.Example at 0x269e5b879b0>,\n",
       " <torchtext.data.example.Example at 0x269e5b87ac8>,\n",
       " <torchtext.data.example.Example at 0x269e5b87b00>,\n",
       " <torchtext.data.example.Example at 0x269e5b87a58>,\n",
       " <torchtext.data.example.Example at 0x269e5bb0eb8>,\n",
       " <torchtext.data.example.Example at 0x269e5bb0ef0>,\n",
       " <torchtext.data.example.Example at 0x269e5bb0f28>,\n",
       " <torchtext.data.example.Example at 0x269e5bb0f60>,\n",
       " <torchtext.data.example.Example at 0x269e5bb0f98>,\n",
       " <torchtext.data.example.Example at 0x269e5bb0fd0>,\n",
       " <torchtext.data.example.Example at 0x269e5bb0e80>,\n",
       " <torchtext.data.example.Example at 0x269e5bb0dd8>,\n",
       " <torchtext.data.example.Example at 0x269e5bb0e10>,\n",
       " <torchtext.data.example.Example at 0x269e5bb0da0>,\n",
       " <torchtext.data.example.Example at 0x269e5bb0d68>,\n",
       " <torchtext.data.example.Example at 0x269e5bb0d30>,\n",
       " <torchtext.data.example.Example at 0x269e5bb0e48>,\n",
       " <torchtext.data.example.Example at 0x269e5bb31d0>,\n",
       " <torchtext.data.example.Example at 0x269e5bb3240>,\n",
       " <torchtext.data.example.Example at 0x269e5bb3278>,\n",
       " <torchtext.data.example.Example at 0x269e5bb30b8>,\n",
       " <torchtext.data.example.Example at 0x269e5bb3080>,\n",
       " <torchtext.data.example.Example at 0x269e5bb3160>,\n",
       " <torchtext.data.example.Example at 0x269e5bb30f0>,\n",
       " <torchtext.data.example.Example at 0x269e5bb3048>,\n",
       " <torchtext.data.example.Example at 0x269e5bb3128>,\n",
       " <torchtext.data.example.Example at 0x269e5bb3198>,\n",
       " <torchtext.data.example.Example at 0x269e5bbe748>,\n",
       " <torchtext.data.example.Example at 0x269e5bbe780>,\n",
       " <torchtext.data.example.Example at 0x269e5bbe7b8>,\n",
       " <torchtext.data.example.Example at 0x269e5bbe7f0>,\n",
       " <torchtext.data.example.Example at 0x269e5bbe828>,\n",
       " <torchtext.data.example.Example at 0x269e5bbe860>,\n",
       " <torchtext.data.example.Example at 0x269e5bbe898>,\n",
       " <torchtext.data.example.Example at 0x269e5bbe908>,\n",
       " <torchtext.data.example.Example at 0x269e5bbe940>,\n",
       " <torchtext.data.example.Example at 0x269e5bbe6d8>,\n",
       " <torchtext.data.example.Example at 0x269e5bbe630>,\n",
       " <torchtext.data.example.Example at 0x269e5bbe5c0>,\n",
       " <torchtext.data.example.Example at 0x269e5bbe710>,\n",
       " <torchtext.data.example.Example at 0x269e5bbe668>,\n",
       " <torchtext.data.example.Example at 0x269e5bbe5f8>,\n",
       " <torchtext.data.example.Example at 0x269e5bbe6a0>,\n",
       " <torchtext.data.example.Example at 0x269e5ca3668>,\n",
       " <torchtext.data.example.Example at 0x269e5ca36a0>,\n",
       " <torchtext.data.example.Example at 0x269e5ca36d8>,\n",
       " <torchtext.data.example.Example at 0x269e5ca3710>,\n",
       " <torchtext.data.example.Example at 0x269e5ca3748>,\n",
       " <torchtext.data.example.Example at 0x269e5ca3780>,\n",
       " <torchtext.data.example.Example at 0x269e5ca37b8>,\n",
       " <torchtext.data.example.Example at 0x269e5ca37f0>,\n",
       " <torchtext.data.example.Example at 0x269e5ca3828>,\n",
       " <torchtext.data.example.Example at 0x269e5ca3860>,\n",
       " <torchtext.data.example.Example at 0x269e5ca3898>,\n",
       " <torchtext.data.example.Example at 0x269e5ca38d0>,\n",
       " <torchtext.data.example.Example at 0x269e5ca3908>,\n",
       " <torchtext.data.example.Example at 0x269e5ca3940>,\n",
       " <torchtext.data.example.Example at 0x269e5ca3978>,\n",
       " <torchtext.data.example.Example at 0x269e5ca39b0>,\n",
       " <torchtext.data.example.Example at 0x269e5ca39e8>,\n",
       " <torchtext.data.example.Example at 0x269e5ca3a20>,\n",
       " <torchtext.data.example.Example at 0x269e5ca3a90>,\n",
       " <torchtext.data.example.Example at 0x269e5ca3ac8>,\n",
       " <torchtext.data.example.Example at 0x269e5ca3630>,\n",
       " <torchtext.data.example.Example at 0x269e5ca3588>,\n",
       " <torchtext.data.example.Example at 0x269e5ca35c0>,\n",
       " <torchtext.data.example.Example at 0x269e5ca69b0>,\n",
       " <torchtext.data.example.Example at 0x269e5ca3518>,\n",
       " <torchtext.data.example.Example at 0x269e5ca35f8>,\n",
       " <torchtext.data.example.Example at 0x269e5ca68d0>,\n",
       " <torchtext.data.example.Example at 0x269e5ca3550>,\n",
       " <torchtext.data.example.Example at 0x269e5ca34e0>,\n",
       " <torchtext.data.example.Example at 0x269e5ca6908>,\n",
       " <torchtext.data.example.Example at 0x269e5ca69e8>,\n",
       " <torchtext.data.example.Example at 0x269e5ca6940>,\n",
       " <torchtext.data.example.Example at 0x269e5cd78d0>,\n",
       " <torchtext.data.example.Example at 0x269e5cd7908>,\n",
       " <torchtext.data.example.Example at 0x269e5cd7940>,\n",
       " <torchtext.data.example.Example at 0x269e5cd7978>,\n",
       " <torchtext.data.example.Example at 0x269e5cd79b0>,\n",
       " <torchtext.data.example.Example at 0x269e5cd7a20>,\n",
       " <torchtext.data.example.Example at 0x269e5cd7a58>,\n",
       " <torchtext.data.example.Example at 0x269e5cd77f0>,\n",
       " <torchtext.data.example.Example at 0x269e5cd7748>,\n",
       " <torchtext.data.example.Example at 0x269e5ce7898>,\n",
       " <torchtext.data.example.Example at 0x269e5cd7780>,\n",
       " <torchtext.data.example.Example at 0x269e5d0cb70>,\n",
       " <torchtext.data.example.Example at 0x269e5d0cba8>,\n",
       " <torchtext.data.example.Example at 0x269e5cd7898>,\n",
       " <torchtext.data.example.Example at 0x269e5ce78d0>,\n",
       " <torchtext.data.example.Example at 0x269e5cd7860>,\n",
       " <torchtext.data.example.Example at 0x269e5ce7828>,\n",
       " <torchtext.data.example.Example at 0x269e5ce77f0>,\n",
       " <torchtext.data.example.Example at 0x269e5cd7828>,\n",
       " <torchtext.data.example.Example at 0x269e5cd77b8>,\n",
       " <torchtext.data.example.Example at 0x269e5d174e0>,\n",
       " <torchtext.data.example.Example at 0x269e5d17518>,\n",
       " <torchtext.data.example.Example at 0x269e5d17550>,\n",
       " <torchtext.data.example.Example at 0x269e5d17588>,\n",
       " <torchtext.data.example.Example at 0x269e5d175c0>,\n",
       " <torchtext.data.example.Example at 0x269e5d175f8>,\n",
       " <torchtext.data.example.Example at 0x269e5d17630>,\n",
       " <torchtext.data.example.Example at 0x269e5d17668>,\n",
       " <torchtext.data.example.Example at 0x269e5d176a0>,\n",
       " <torchtext.data.example.Example at 0x269e5d176d8>,\n",
       " <torchtext.data.example.Example at 0x269e5d17710>,\n",
       " <torchtext.data.example.Example at 0x269e5d17748>,\n",
       " <torchtext.data.example.Example at 0x269e5d17780>,\n",
       " <torchtext.data.example.Example at 0x269e5d177b8>,\n",
       " <torchtext.data.example.Example at 0x269e5d177f0>,\n",
       " <torchtext.data.example.Example at 0x269e5d17828>,\n",
       " <torchtext.data.example.Example at 0x269e5d17860>,\n",
       " <torchtext.data.example.Example at 0x269e5d17898>,\n",
       " <torchtext.data.example.Example at 0x269e5d178d0>,\n",
       " <torchtext.data.example.Example at 0x269e5d17908>,\n",
       " <torchtext.data.example.Example at 0x269e5d17978>,\n",
       " <torchtext.data.example.Example at 0x269e5d179b0>,\n",
       " <torchtext.data.example.Example at 0x269e5d17358>,\n",
       " <torchtext.data.example.Example at 0x269e5d17470>,\n",
       " <torchtext.data.example.Example at 0x269e5d17400>,\n",
       " <torchtext.data.example.Example at 0x269e5d3a9b0>,\n",
       " <torchtext.data.example.Example at 0x269e5d174a8>,\n",
       " <torchtext.data.example.Example at 0x269e5d17390>,\n",
       " <torchtext.data.example.Example at 0x269e5d3a8d0>,\n",
       " <torchtext.data.example.Example at 0x269e5d17438>,\n",
       " <torchtext.data.example.Example at 0x269e5d173c8>,\n",
       " <torchtext.data.example.Example at 0x269e5d3a908>,\n",
       " <torchtext.data.example.Example at 0x269e5d3a9e8>,\n",
       " <torchtext.data.example.Example at 0x269e5d3a940>,\n",
       " <torchtext.data.example.Example at 0x269e5d41400>,\n",
       " <torchtext.data.example.Example at 0x269e5d41438>,\n",
       " <torchtext.data.example.Example at 0x269e5d41470>,\n",
       " <torchtext.data.example.Example at 0x269e5d414a8>,\n",
       " <torchtext.data.example.Example at 0x269e5d414e0>,\n",
       " <torchtext.data.example.Example at 0x269e5d41518>,\n",
       " <torchtext.data.example.Example at 0x269e5d41550>,\n",
       " <torchtext.data.example.Example at 0x269e5d41588>,\n",
       " <torchtext.data.example.Example at 0x269e5d415c0>,\n",
       " <torchtext.data.example.Example at 0x269e5d415f8>,\n",
       " <torchtext.data.example.Example at 0x269e5d41630>,\n",
       " <torchtext.data.example.Example at 0x269e5d41668>,\n",
       " <torchtext.data.example.Example at 0x269e5d416a0>,\n",
       " <torchtext.data.example.Example at 0x269e5d416d8>,\n",
       " <torchtext.data.example.Example at 0x269e5d41710>,\n",
       " <torchtext.data.example.Example at 0x269e5d41748>,\n",
       " <torchtext.data.example.Example at 0x269e5d41780>,\n",
       " <torchtext.data.example.Example at 0x269e5d417b8>,\n",
       " <torchtext.data.example.Example at 0x269e5d417f0>,\n",
       " <torchtext.data.example.Example at 0x269e5d41828>,\n",
       " <torchtext.data.example.Example at 0x269e5d41860>,\n",
       " <torchtext.data.example.Example at 0x269e5d418d0>,\n",
       " <torchtext.data.example.Example at 0x269e5d41908>,\n",
       " <torchtext.data.example.Example at 0x269e5d69eb8>,\n",
       " <torchtext.data.example.Example at 0x269e5d69f28>,\n",
       " <torchtext.data.example.Example at 0x269e5d412b0>,\n",
       " <torchtext.data.example.Example at 0x269e5de5f60>,\n",
       " <torchtext.data.example.Example at 0x269e5de5f98>,\n",
       " <torchtext.data.example.Example at 0x269e5d41320>,\n",
       " <torchtext.data.example.Example at 0x269e5d413c8>,\n",
       " <torchtext.data.example.Example at 0x269e5de5ef0>,\n",
       " <torchtext.data.example.Example at 0x269e5d41278>,\n",
       " <torchtext.data.example.Example at 0x269e5d41358>,\n",
       " <torchtext.data.example.Example at 0x269e5d41390>,\n",
       " <torchtext.data.example.Example at 0x269e5d412e8>,\n",
       " <torchtext.data.example.Example at 0x269e5dec2b0>,\n",
       " <torchtext.data.example.Example at 0x269e5dec2e8>,\n",
       " <torchtext.data.example.Example at 0x269e5dec320>,\n",
       " <torchtext.data.example.Example at 0x269e5dec358>,\n",
       " <torchtext.data.example.Example at 0x269e5dec390>,\n",
       " <torchtext.data.example.Example at 0x269e5dec3c8>,\n",
       " <torchtext.data.example.Example at 0x269e5dec400>,\n",
       " <torchtext.data.example.Example at 0x269e5dec438>,\n",
       " <torchtext.data.example.Example at 0x269e5dec470>,\n",
       " <torchtext.data.example.Example at 0x269e5dec4a8>,\n",
       " <torchtext.data.example.Example at 0x269e5dec4e0>,\n",
       " <torchtext.data.example.Example at 0x269e5dec518>,\n",
       " <torchtext.data.example.Example at 0x269e5dec550>,\n",
       " <torchtext.data.example.Example at 0x269e5dec588>,\n",
       " <torchtext.data.example.Example at 0x269e5dec5c0>,\n",
       " <torchtext.data.example.Example at 0x269e5dec630>,\n",
       " <torchtext.data.example.Example at 0x269e5dec668>,\n",
       " <torchtext.data.example.Example at 0x269e5dec198>,\n",
       " <torchtext.data.example.Example at 0x269e5dec160>,\n",
       " <torchtext.data.example.Example at 0x269e5dec240>,\n",
       " <torchtext.data.example.Example at 0x269e5dec1d0>,\n",
       " <torchtext.data.example.Example at 0x269e5e67f60>,\n",
       " <torchtext.data.example.Example at 0x269e5dec208>,\n",
       " <torchtext.data.example.Example at 0x269e5e69048>,\n",
       " <torchtext.data.example.Example at 0x269e5e69080>,\n",
       " <torchtext.data.example.Example at 0x269e5e7dac8>,\n",
       " <torchtext.data.example.Example at 0x269e5e67f28>,\n",
       " <torchtext.data.example.Example at 0x269e5dec278>,\n",
       " <torchtext.data.example.Example at 0x269e5e80dd8>,\n",
       " <torchtext.data.example.Example at 0x269e5e67ef0>,\n",
       " <torchtext.data.example.Example at 0x269e5dec128>,\n",
       " <torchtext.data.example.Example at 0x269e5e80d68>,\n",
       " <torchtext.data.example.Example at 0x269e5e67f98>,\n",
       " <torchtext.data.example.Example at 0x269e5e80e10>,\n",
       " <torchtext.data.example.Example at 0x269e5e80d30>,\n",
       " <torchtext.data.example.Example at 0x269e5e81668>,\n",
       " <torchtext.data.example.Example at 0x269e5e816a0>,\n",
       " <torchtext.data.example.Example at 0x269e5e67e80>,\n",
       " <torchtext.data.example.Example at 0x269e5e815f8>,\n",
       " <torchtext.data.example.Example at 0x269e5e81588>,\n",
       " <torchtext.data.example.Example at 0x269e5e67eb8>,\n",
       " <torchtext.data.example.Example at 0x269e5e815c0>,\n",
       " <torchtext.data.example.Example at 0x269e5e81550>,\n",
       " <torchtext.data.example.Example at 0x269e5e81518>,\n",
       " <torchtext.data.example.Example at 0x269e5ea7208>,\n",
       " <torchtext.data.example.Example at 0x269e5ea7240>,\n",
       " <torchtext.data.example.Example at 0x269e5ea7278>,\n",
       " <torchtext.data.example.Example at 0x269e5ea72b0>,\n",
       " <torchtext.data.example.Example at 0x269e5ea72e8>,\n",
       " <torchtext.data.example.Example at 0x269e5ea7320>,\n",
       " <torchtext.data.example.Example at 0x269e5ea7358>,\n",
       " <torchtext.data.example.Example at 0x269e5ea7390>,\n",
       " <torchtext.data.example.Example at 0x269e5ea7400>,\n",
       " <torchtext.data.example.Example at 0x269e5ea7438>,\n",
       " <torchtext.data.example.Example at 0x269e5ea70f0>,\n",
       " <torchtext.data.example.Example at 0x269e5ea70b8>,\n",
       " <torchtext.data.example.Example at 0x269e5ea7198>,\n",
       " <torchtext.data.example.Example at 0x269e5ea7128>,\n",
       " <torchtext.data.example.Example at 0x269e5ea7080>,\n",
       " <torchtext.data.example.Example at 0x269e5ea7160>,\n",
       " <torchtext.data.example.Example at 0x269e5ea71d0>,\n",
       " <torchtext.data.example.Example at 0x269e5eb46a0>,\n",
       " <torchtext.data.example.Example at 0x269e5eb46d8>,\n",
       " <torchtext.data.example.Example at 0x269e5eb4710>,\n",
       " <torchtext.data.example.Example at 0x269e5eb4748>,\n",
       " <torchtext.data.example.Example at 0x269e5eb4780>,\n",
       " <torchtext.data.example.Example at 0x269e5eb47f0>,\n",
       " <torchtext.data.example.Example at 0x269e5eb4828>,\n",
       " <torchtext.data.example.Example at 0x269e5eb45c0>,\n",
       " <torchtext.data.example.Example at 0x269e5eb4518>,\n",
       " <torchtext.data.example.Example at 0x269e5ebb1d0>,\n",
       " <torchtext.data.example.Example at 0x269e5eb4550>,\n",
       " <torchtext.data.example.Example at 0x269e5ed3fd0>,\n",
       " <torchtext.data.example.Example at 0x269e5ef2eb8>,\n",
       " <torchtext.data.example.Example at 0x269e5ef2f98>,\n",
       " <torchtext.data.example.Example at 0x269e5ef2f60>,\n",
       " <torchtext.data.example.Example at 0x269e5ef2ef0>,\n",
       " <torchtext.data.example.Example at 0x269e5f0e9b0>,\n",
       " <torchtext.data.example.Example at 0x269e5f0e9e8>,\n",
       " <torchtext.data.example.Example at 0x269e5f0ea20>,\n",
       " <torchtext.data.example.Example at 0x269e5f0ea58>,\n",
       " <torchtext.data.example.Example at 0x269e5f0eac8>,\n",
       " <torchtext.data.example.Example at 0x269e5f0eb00>,\n",
       " <torchtext.data.example.Example at 0x269e5f0e978>,\n",
       " <torchtext.data.example.Example at 0x269e5f0e908>,\n",
       " <torchtext.data.example.Example at 0x269e5f0e940>,\n",
       " <torchtext.data.example.Example at 0x269e5f0e860>,\n",
       " <torchtext.data.example.Example at 0x269e5f0e898>,\n",
       " <torchtext.data.example.Example at 0x269e5f0e828>,\n",
       " <torchtext.data.example.Example at 0x269e5f0e8d0>,\n",
       " <torchtext.data.example.Example at 0x269e5f3ef98>,\n",
       " <torchtext.data.example.Example at 0x269e5f3efd0>,\n",
       " <torchtext.data.example.Example at 0x269e5f3ef28>,\n",
       " <torchtext.data.example.Example at 0x269e5f3ee80>,\n",
       " <torchtext.data.example.Example at 0x269e5f3ee10>,\n",
       " <torchtext.data.example.Example at 0x269e5f3ef60>,\n",
       " <torchtext.data.example.Example at 0x269e5f3eeb8>,\n",
       " <torchtext.data.example.Example at 0x269e5f3ee48>,\n",
       " <torchtext.data.example.Example at 0x269e5f3eef0>,\n",
       " <torchtext.data.example.Example at 0x269e5f3f1d0>,\n",
       " <torchtext.data.example.Example at 0x269e5f3f208>,\n",
       " <torchtext.data.example.Example at 0x269e5f3f240>,\n",
       " <torchtext.data.example.Example at 0x269e5f3f278>,\n",
       " <torchtext.data.example.Example at 0x269e5f3f2b0>,\n",
       " <torchtext.data.example.Example at 0x269e5f3f320>,\n",
       " <torchtext.data.example.Example at 0x269e5f3f358>,\n",
       " <torchtext.data.example.Example at 0x269e5ec0cf8>,\n",
       " <torchtext.data.example.Example at 0x269e5ec9eb8>,\n",
       " <torchtext.data.example.Example at 0x269e5ed9390>,\n",
       " <torchtext.data.example.Example at 0x269e5ecae10>,\n",
       " <torchtext.data.example.Example at 0x269e5ecadd8>,\n",
       " <torchtext.data.example.Example at 0x269e5f3f128>,\n",
       " <torchtext.data.example.Example at 0x269e5f3f198>,\n",
       " <torchtext.data.example.Example at 0x269e5f3f080>,\n",
       " <torchtext.data.example.Example at 0x269e5f3f160>,\n",
       " <torchtext.data.example.Example at 0x269e5ebb208>,\n",
       " <torchtext.data.example.Example at 0x269e5f3f0f0>,\n",
       " <torchtext.data.example.Example at 0x269e5ec16a0>,\n",
       " <torchtext.data.example.Example at 0x269e5ebc208>,\n",
       " <torchtext.data.example.Example at 0x269e5ebc7f0>,\n",
       " <torchtext.data.example.Example at 0x269e5eb9278>,\n",
       " <torchtext.data.example.Example at 0x269e5f3f048>,\n",
       " <torchtext.data.example.Example at 0x269e5ebb160>,\n",
       " <torchtext.data.example.Example at 0x269e5ebb240>,\n",
       " <torchtext.data.example.Example at 0x269e5f3f0b8>,\n",
       " <torchtext.data.example.Example at 0x269e5eb47b8>,\n",
       " <torchtext.data.example.Example at 0x269e5ebb358>,\n",
       " <torchtext.data.example.Example at 0x269e5eb5400>,\n",
       " <torchtext.data.example.Example at 0x269e5ea73c8>,\n",
       " <torchtext.data.example.Example at 0x269e5ea7a58>,\n",
       " <torchtext.data.example.Example at 0x269e5e80da0>,\n",
       " <torchtext.data.example.Example at 0x269e5e67fd0>,\n",
       " <torchtext.data.example.Example at 0x269e5eabb00>,\n",
       " <torchtext.data.example.Example at 0x269e5e81630>,\n",
       " <torchtext.data.example.Example at 0x269e5eb4668>,\n",
       " <torchtext.data.example.Example at 0x269e5ebb198>,\n",
       " <torchtext.data.example.Example at 0x269e5eb4e80>,\n",
       " <torchtext.data.example.Example at 0x269e5fc2f98>,\n",
       " <torchtext.data.example.Example at 0x269e5ebb278>,\n",
       " <torchtext.data.example.Example at 0x269e5eb4588>,\n",
       " <torchtext.data.example.Example at 0x269e5fc30b8>,\n",
       " <torchtext.data.example.Example at 0x269e5fc30f0>,\n",
       " <torchtext.data.example.Example at 0x269e5fc2f60>,\n",
       " <torchtext.data.example.Example at 0x269e5eb4630>,\n",
       " <torchtext.data.example.Example at 0x269e5fc3048>,\n",
       " <torchtext.data.example.Example at 0x269e5fc2f28>,\n",
       " <torchtext.data.example.Example at 0x269e5eb45f8>,\n",
       " <torchtext.data.example.Example at 0x269e5fc2ef0>,\n",
       " <torchtext.data.example.Example at 0x269e5fc2fd0>,\n",
       " <torchtext.data.example.Example at 0x269e5fc8320>,\n",
       " <torchtext.data.example.Example at 0x269e5fc8358>,\n",
       " <torchtext.data.example.Example at 0x269e5fc8390>,\n",
       " <torchtext.data.example.Example at 0x269e5fc83c8>,\n",
       " <torchtext.data.example.Example at 0x269e5fc8400>,\n",
       " <torchtext.data.example.Example at 0x269e5fc8438>,\n",
       " <torchtext.data.example.Example at 0x269e5fc84e0>,\n",
       " <torchtext.data.example.Example at 0x269e5fc9da0>,\n",
       " <torchtext.data.example.Example at 0x269e5fc8198>,\n",
       " <torchtext.data.example.Example at 0x269e5fc82b0>,\n",
       " <torchtext.data.example.Example at 0x269e5fc8240>,\n",
       " <torchtext.data.example.Example at 0x269e5fc8278>,\n",
       " <torchtext.data.example.Example at 0x269e5fc82e8>,\n",
       " <torchtext.data.example.Example at 0x269e5fc8208>,\n",
       " <torchtext.data.example.Example at 0x269e5fc81d0>,\n",
       " <torchtext.data.example.Example at 0x269e5fe7a90>,\n",
       " <torchtext.data.example.Example at 0x269e5fe7ac8>,\n",
       " <torchtext.data.example.Example at 0x269e5fe79e8>,\n",
       " <torchtext.data.example.Example at 0x269e5fe7940>,\n",
       " <torchtext.data.example.Example at 0x269e5fea3c8>,\n",
       " <torchtext.data.example.Example at 0x269e5fe7a20>,\n",
       " <torchtext.data.example.Example at 0x269e5fe7908>,\n",
       " <torchtext.data.example.Example at 0x269e5fea358>,\n",
       " <torchtext.data.example.Example at 0x269e5fe79b0>,\n",
       " <torchtext.data.example.Example at 0x269e5ff57f0>,\n",
       " <torchtext.data.example.Example at 0x269e5fea320>,\n",
       " <torchtext.data.example.Example at 0x269e5fe7978>,\n",
       " <torchtext.data.example.Example at 0x269e5ff5710>,\n",
       " <torchtext.data.example.Example at 0x269e5fea400>,\n",
       " <torchtext.data.example.Example at 0x269e5fe78d0>,\n",
       " <torchtext.data.example.Example at 0x269e5ff5748>,\n",
       " <torchtext.data.example.Example at 0x269e5ff5828>,\n",
       " <torchtext.data.example.Example at 0x269e5ff5780>,\n",
       " <torchtext.data.example.Example at 0x269e5ff61d0>,\n",
       " <torchtext.data.example.Example at 0x269e5ff6208>,\n",
       " <torchtext.data.example.Example at 0x269e5ff6240>,\n",
       " <torchtext.data.example.Example at 0x269e5ff6278>,\n",
       " <torchtext.data.example.Example at 0x269e5ff62b0>,\n",
       " <torchtext.data.example.Example at 0x269e5ff6320>,\n",
       " <torchtext.data.example.Example at 0x269e5ff6358>,\n",
       " <torchtext.data.example.Example at 0x269e5ff60f0>,\n",
       " <torchtext.data.example.Example at 0x269e5ff6048>,\n",
       " <torchtext.data.example.Example at 0x269e5ff6198>,\n",
       " <torchtext.data.example.Example at 0x269e5ff6080>,\n",
       " <torchtext.data.example.Example at 0x269e5ff6128>,\n",
       " <torchtext.data.example.Example at 0x269e5ff6160>,\n",
       " <torchtext.data.example.Example at 0x269e5ff60b8>,\n",
       " <torchtext.data.example.Example at 0x269e604d940>,\n",
       " <torchtext.data.example.Example at 0x269e604d978>,\n",
       " <torchtext.data.example.Example at 0x269e604d9e8>,\n",
       " <torchtext.data.example.Example at 0x269e604da20>,\n",
       " <torchtext.data.example.Example at 0x269e604d7f0>,\n",
       " <torchtext.data.example.Example at 0x269e6050f98>,\n",
       " <torchtext.data.example.Example at 0x269e6050fd0>,\n",
       " <torchtext.data.example.Example at 0x269e604d860>,\n",
       " <torchtext.data.example.Example at 0x269e604d908>,\n",
       " <torchtext.data.example.Example at 0x269e6050f60>,\n",
       " <torchtext.data.example.Example at 0x269e6051128>,\n",
       " <torchtext.data.example.Example at 0x269e604d898>,\n",
       " <torchtext.data.example.Example at 0x269e6075f98>,\n",
       " <torchtext.data.example.Example at 0x269e6075fd0>,\n",
       " <torchtext.data.example.Example at 0x269e604d7b8>,\n",
       " <torchtext.data.example.Example at 0x269e60510b8>,\n",
       " <torchtext.data.example.Example at 0x269e604d828>,\n",
       " <torchtext.data.example.Example at 0x269e604d8d0>,\n",
       " <torchtext.data.example.Example at 0x269e6051160>,\n",
       " <torchtext.data.example.Example at 0x269e6051048>,\n",
       " <torchtext.data.example.Example at 0x269e6051080>,\n",
       " <torchtext.data.example.Example at 0x269e607b208>,\n",
       " <torchtext.data.example.Example at 0x269e607b240>,\n",
       " <torchtext.data.example.Example at 0x269e60a5780>,\n",
       " <torchtext.data.example.Example at 0x269e60a57b8>,\n",
       " <torchtext.data.example.Example at 0x269e607b080>,\n",
       " <torchtext.data.example.Example at 0x269e607b128>,\n",
       " <torchtext.data.example.Example at 0x269e607b0b8>,\n",
       " <torchtext.data.example.Example at 0x269e607b048>,\n",
       " <torchtext.data.example.Example at 0x269e607b160>,\n",
       " <torchtext.data.example.Example at 0x269e60d0c88>,\n",
       " <torchtext.data.example.Example at 0x269e60d0cc0>,\n",
       " <torchtext.data.example.Example at 0x269e607b198>,\n",
       " <torchtext.data.example.Example at 0x269e60d0c18>,\n",
       " <torchtext.data.example.Example at 0x269e60d0ba8>,\n",
       " <torchtext.data.example.Example at 0x269e607b0f0>,\n",
       " <torchtext.data.example.Example at 0x269e60d5780>,\n",
       " <torchtext.data.example.Example at 0x269e60d0b70>,\n",
       " <torchtext.data.example.Example at 0x269e60d0be0>,\n",
       " <torchtext.data.example.Example at 0x269e60d30f0>,\n",
       " <torchtext.data.example.Example at 0x269e60d3128>,\n",
       " <torchtext.data.example.Example at 0x269e60d56d8>,\n",
       " <torchtext.data.example.Example at 0x269e60d0b38>,\n",
       " <torchtext.data.example.Example at 0x269e60d3080>,\n",
       " <torchtext.data.example.Example at 0x269e60d56a0>,\n",
       " <torchtext.data.example.Example at 0x269e60d5630>,\n",
       " <torchtext.data.example.Example at 0x269e60d5668>,\n",
       " <torchtext.data.example.Example at 0x269e60d57b8>,\n",
       " <torchtext.data.example.Example at 0x269e60dedd8>,\n",
       " <torchtext.data.example.Example at 0x269e60dee10>,\n",
       " <torchtext.data.example.Example at 0x269e60dee48>,\n",
       " <torchtext.data.example.Example at 0x269e60dee80>,\n",
       " <torchtext.data.example.Example at 0x269e60deeb8>,\n",
       " <torchtext.data.example.Example at 0x269e60deef0>,\n",
       " <torchtext.data.example.Example at 0x269e60def28>,\n",
       " <torchtext.data.example.Example at 0x269e60def60>,\n",
       " <torchtext.data.example.Example at 0x269e60def98>,\n",
       " <torchtext.data.example.Example at 0x269e60e1048>,\n",
       " <torchtext.data.example.Example at 0x269e60e1080>,\n",
       " <torchtext.data.example.Example at 0x269e60dec88>,\n",
       " <torchtext.data.example.Example at 0x269e6101908>,\n",
       " <torchtext.data.example.Example at 0x269e6101940>,\n",
       " <torchtext.data.example.Example at 0x269e60decf8>,\n",
       " <torchtext.data.example.Example at 0x269e60deda0>,\n",
       " <torchtext.data.example.Example at 0x269e6101898>,\n",
       " <torchtext.data.example.Example at 0x269e60dec50>,\n",
       " <torchtext.data.example.Example at 0x269e60ded30>,\n",
       " <torchtext.data.example.Example at 0x269e6115ef0>,\n",
       " <torchtext.data.example.Example at 0x269e6115f28>,\n",
       " <torchtext.data.example.Example at 0x269e611f278>,\n",
       " <torchtext.data.example.Example at 0x269e611f2b0>,\n",
       " <torchtext.data.example.Example at 0x269e6115dd8>,\n",
       " <torchtext.data.example.Example at 0x269e6115da0>,\n",
       " <torchtext.data.example.Example at 0x269e61282e8>,\n",
       " <torchtext.data.example.Example at 0x269e6115e10>,\n",
       " <torchtext.data.example.Example at 0x269e60decc0>,\n",
       " <torchtext.data.example.Example at 0x269e61319e8>,\n",
       " <torchtext.data.example.Example at 0x269e6131a20>,\n",
       " <torchtext.data.example.Example at 0x269e6128320>,\n",
       " <torchtext.data.example.Example at 0x269e6115e48>,\n",
       " <torchtext.data.example.Example at 0x269e6131978>,\n",
       " <torchtext.data.example.Example at 0x269e60ded68>,\n",
       " <torchtext.data.example.Example at 0x269e6115e80>,\n",
       " <torchtext.data.example.Example at 0x269e6128278>,\n",
       " <torchtext.data.example.Example at 0x269e6128240>,\n",
       " <torchtext.data.example.Example at 0x269e614f240>,\n",
       " <torchtext.data.example.Example at 0x269e614f278>,\n",
       " <torchtext.data.example.Example at 0x269e614f2b0>,\n",
       " <torchtext.data.example.Example at 0x269e614f2e8>,\n",
       " <torchtext.data.example.Example at 0x269e614f390>,\n",
       " <torchtext.data.example.Example at 0x269e614e550>,\n",
       " <torchtext.data.example.Example at 0x269e6162cc0>,\n",
       " <torchtext.data.example.Example at 0x269e6162d30>,\n",
       " <torchtext.data.example.Example at 0x269e6166b00>,\n",
       " <torchtext.data.example.Example at 0x269e616c438>,\n",
       " <torchtext.data.example.Example at 0x269e614f128>,\n",
       " <torchtext.data.example.Example at 0x269e614f0f0>,\n",
       " <torchtext.data.example.Example at 0x269e614f1d0>,\n",
       " <torchtext.data.example.Example at 0x269e614f160>,\n",
       " <torchtext.data.example.Example at 0x269e614f0b8>,\n",
       " <torchtext.data.example.Example at 0x269e614f198>,\n",
       " <torchtext.data.example.Example at 0x269e614f208>,\n",
       " <torchtext.data.example.Example at 0x269e6172ef0>,\n",
       " <torchtext.data.example.Example at 0x269e6172f28>,\n",
       " <torchtext.data.example.Example at 0x269e6172f60>,\n",
       " <torchtext.data.example.Example at 0x269e6172f98>,\n",
       " <torchtext.data.example.Example at 0x269e6172fd0>,\n",
       " <torchtext.data.example.Example at 0x269e6173080>,\n",
       " <torchtext.data.example.Example at 0x269e61730b8>,\n",
       " <torchtext.data.example.Example at 0x269e617ffd0>,\n",
       " <torchtext.data.example.Example at 0x269e6172d68>,\n",
       " <torchtext.data.example.Example at 0x269e6172e80>,\n",
       " <torchtext.data.example.Example at 0x269e6172e10>,\n",
       " <torchtext.data.example.Example at 0x269e6172e48>,\n",
       " <torchtext.data.example.Example at 0x269e6172eb8>,\n",
       " <torchtext.data.example.Example at 0x269e6172dd8>,\n",
       " <torchtext.data.example.Example at 0x269e6172da0>,\n",
       " <torchtext.data.example.Example at 0x269e61801d0>,\n",
       " <torchtext.data.example.Example at 0x269e6180208>,\n",
       " <torchtext.data.example.Example at 0x269e6180240>,\n",
       " <torchtext.data.example.Example at 0x269e6180278>,\n",
       " <torchtext.data.example.Example at 0x269e61802b0>,\n",
       " <torchtext.data.example.Example at 0x269e61802e8>,\n",
       " <torchtext.data.example.Example at 0x269e6180320>,\n",
       " <torchtext.data.example.Example at 0x269e6180358>,\n",
       " <torchtext.data.example.Example at 0x269e61803c8>,\n",
       " <torchtext.data.example.Example at 0x269e6180400>,\n",
       " <torchtext.data.example.Example at 0x269e61800b8>,\n",
       " <torchtext.data.example.Example at 0x269e6180080>,\n",
       " <torchtext.data.example.Example at 0x269e6180160>,\n",
       " <torchtext.data.example.Example at 0x269e61800f0>,\n",
       " ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['bromwell', 'high', 'is', 'a', 'cartoon', 'comedy.', 'it', 'ran', 'at', 'the', 'same', 'time', 'as', 'some', 'other', 'programs', 'about', 'school', 'life,', 'such', 'as', '\"teachers\".', 'my', '35', 'years', 'in', 'the', 'teaching', 'profession', 'lead', 'me', 'to', 'believe', 'that', 'bromwell', \"high's\", 'satire', 'is', 'much', 'closer', 'to', 'reality', 'than', 'is', '\"teachers\".', 'the', 'scramble', 'to', 'survive', 'financially,', 'the', 'insightful', 'students', 'who', 'can', 'see', 'right', 'through', 'their', 'pathetic', \"teachers'\", 'pomp,', 'the', 'pettiness', 'of', 'the', 'whole', 'situation,', 'all', 'remind', 'me', 'of', 'the', 'schools', 'i', 'knew', 'and', 'their', 'students.', 'when', 'i', 'saw', 'the', 'episode', 'in', 'which', 'a', 'student', 'repeatedly', 'tried', 'to', 'burn', 'down', 'the', 'school,', 'i', 'immediately', 'recalled', '.........', 'at', '..........', 'high.', 'a', 'classic', 'line:', 'inspector:', \"i'm\", 'here', 'to', 'sack', 'one', 'of', 'your', 'teachers.', 'student:', 'welcome', 'to', 'bromwell', 'high.', 'i', 'expect', 'that', 'many', 'adults', 'of', 'my', 'age', 'think', 'that', 'bromwell', 'high', 'is', 'far', 'fetched.', 'what', 'a', 'pity', 'that', 'it', \"isn't!\"], 'label': 'pos'}\n"
     ]
    }
   ],
   "source": [
    "#let's look at the sample example of the train_data\n",
    "print(vars(train_data.examples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE LENGTH OF THE TRAIN DATA IS : 25000\n",
      "THE LENGTH OF THE TEST DATA IS : 19267\n"
     ]
    }
   ],
   "source": [
    "#let's check the length of the train and test data\n",
    "print(f\"THE LENGTH OF THE TRAIN DATA IS : {len(train_data)}\")\n",
    "print(f\"THE LENGTH OF THE TEST DATA IS : {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will spit our train data further into training and validation\n",
    "train_data, val_data = train_data.split(split_ratio = 0.7, random_state = random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE LENGTH OF THE TRAIN DATA IS : 17500\n",
      "THE LENGTH OF THE VAL DATA IS : 7500\n",
      "THE LENGTH OF THE TEST DATA IS : 25000\n"
     ]
    }
   ],
   "source": [
    "#let's check the length of the train and test data and val data\n",
    "print(f\"THE LENGTH OF THE TRAIN DATA IS : {len(train_data)}\")\n",
    "print(f\"THE LENGTH OF THE VAL DATA IS : {len(val_data)}\")\n",
    "print(f\"THE LENGTH OF THE TEST DATA IS : {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Next, we have to build a vocabulary. This is a effectively a look up table where every unique word in your data set has a corresponding index (an integer).\n",
    "\n",
    "We do this as our machine learning model cannot operate on strings, only numbers. Each index is used to construct a one-hot vector for each word. A one-hot vector is a vector where all of the elements are 0, except one, which is 1, and dimensionality is the total number of unique words in your vocabulary, commonly denoted by $V$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "a bytes-like object is required, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj, include, exclude)\u001b[0m\n\u001b[0;32m    968\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    969\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 970\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    971\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\IPython\\core\\display.py\u001b[0m in \u001b[0;36m_repr_mimebundle_\u001b[1;34m(self, include, exclude)\u001b[0m\n\u001b[0;32m   1207\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1208\u001b[0m             \u001b[0mmimetype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mimetype\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1209\u001b[1;33m             \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetadata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data_and_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malways_both\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1210\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1211\u001b[0m                 \u001b[0mmetadata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mmimetype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\IPython\\core\\display.py\u001b[0m in \u001b[0;36m_data_and_metadata\u001b[1;34m(self, always_both)\u001b[0m\n\u001b[0;32m   1216\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_data_and_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malways_both\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1217\u001b[0m         \u001b[1;34m\"\"\"shortcut for returning metadata with shape information, if defined\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1218\u001b[1;33m         \u001b[0mb64_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb2a_base64\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ascii'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1219\u001b[0m         \u001b[0mmd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1220\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "a bytes-like object is required, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\IPython\\core\\display.py\u001b[0m in \u001b[0;36m_repr_png_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1233\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_repr_png_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1234\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membed\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FMT_PNG\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1235\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data_and_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1237\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_repr_jpeg_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\IPython\\core\\display.py\u001b[0m in \u001b[0;36m_data_and_metadata\u001b[1;34m(self, always_both)\u001b[0m\n\u001b[0;32m   1216\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_data_and_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malways_both\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1217\u001b[0m         \u001b[1;34m\"\"\"shortcut for returning metadata with shape information, if defined\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1218\u001b[1;33m         \u001b[0mb64_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb2a_base64\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ascii'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1219\u001b[0m         \u001b[0mmd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1220\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example of how the index for each word can be used to obatin the OHE of the corresponding word\n",
    "from IPython.display import Image\n",
    "Image('table.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of unique words in our training set is over 100,000, which means that our one-hot vectors will have over 100,000 dimensions! This will make training slow and possibly won't fit onto your GPU (if you're using one).\n",
    "\n",
    "There are two ways effectively cut down our vocabulary, we can either only take the top $n$ most common words or ignore words that appear less than $m$ times. We'll do the former, only keeping the top 25,000 words.\n",
    "\n",
    "What do we do with words that appear in examples but we have cut from the vocabulary? We replace them with a special unknown or $<unk>$ token. For example, if the sentence was \"This film is great and I love it\" but the word \"love\" was not in the vocabulary, it would become \"This film is great and I $<unk>$ it\".\n",
    "\n",
    "The following builds the vocabulary, only keeping the most common max_size tokens.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's build the vcabulary by keeping the max_size = 25,000\n",
    "TEXT.build_vocab(train_data, max_size = 25000)\n",
    "LABEL.build_vocab(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE LENGTH OF THE TEXT VOCAB IS : 25002\n",
      "THE LENGTH OF THE LABEL VOCAB IS : 2\n"
     ]
    }
   ],
   "source": [
    "#let's check the length of our vocabulary\n",
    "print(f\"THE LENGTH OF THE TEXT VOCAB IS : {len(TEXT.vocab)}\")\n",
    "print(f\"THE LENGTH OF THE LABEL VOCAB IS : {len(LABEL.vocab)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the size of our TEXT vocabulary is 25002 (25000 because we mentioned that we want the max size of the vocabulary to be 25000 and additional 2 because of the fake tokens of $<unk>$ token and $<pad>$ token.\n",
    "\n",
    "The length of the LABEL vocab is 2 because we have two different classes of $pos$ and $neg$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 224887), ('a', 111557), ('and', 110593), ('of', 100616), ('to', 93640), ('is', 72251), ('in', 63402), ('i', 49253), ('this', 48412), ('that', 46215), ('it', 45621), ('/><br', 35559), ('was', 32892), ('as', 31290), ('for', 29951), ('with', 29874), ('but', 27735), ('on', 21968), ('movie', 21391), ('his', 20331)]\n"
     ]
    }
   ],
   "source": [
    "#let's also view the most common words and their frequency in the vocabulary\n",
    "print(TEXT.vocab.freqs.most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('pos', 12500), ('neg', 12500)]\n"
     ]
    }
   ],
   "source": [
    "#also we can see the total number of examples belonging to each of the 'pos' and 'neg' sentiments\n",
    "print(LABEL.vocab.freqs.most_common())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see the vocabulary directly using either the stoi (string to int) or itos (int to string) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<unk>', '<pad>', 'the', 'a', 'and', 'of', 'to', 'is', 'in', 'i']\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.itos[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step of preparing the data is creating the iterators. We iterate over these in the training/evaluation loop, and they return a batch of examples (indexed and converted into tensors) at each iteration.\n",
    "\n",
    "We'll use a BucketIterator which is a special type of iterator that will return a batch of examples where each example is of a similar length, minimizing the amount of padding per example.\n",
    "\n",
    "We also want to place the tensors returned by the iterator on the GPU (if you're using one). PyTorch handles this using torch.device, we then pass this device to the iterator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits((train_data, val_data, test_data),\n",
    "                                                                           batch_size = BATCH_SIZE,\n",
    "                                                                           device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['blonde', 'and', 'blonder', 'was', 'unfunny.basically,', 'it', 'was', 'a', 'rip-off', 'girl', 'version', 'of', 'dumb', 'and', 'dumber,', 'but', 'less', 'funny,', 'and', 'they', 'used', 'too', 'much', 'background', 'noises', 'and', 'music.way', 'too', 'much', 'background', 'noises', 'and', 'music', 'if', 'you', 'ask', 'me!!!!it', 'starts', 'out', 'immensely', 'boring,', 'and', 'totally', 'inane.it', \"doesn't\", 'pick', 'up', 'pace', 'anywhere', 'soon,', 'and', 'i', 'was', 'feeling', 'more', 'frustrated', 'as', 'this', 'nonsense', 'carried', 'on.maybe,', 'the', 'only', 'thing', 'that', 'saved', 'me', 'from', 'giving', 'this', 'movie', 'a', '1', 'was', 'the', 'last', '30', 'minutes.i', 'found', 'it', 'somewhat', 'entertaining', 'and', 'interesting', 'as', 'it', 'neared', 'the', 'end,', 'but', 'that', 'was', 'the', 'only', 'part.also,', 'i', \"couldn't\", 'help', 'but', 'like', 'pamela', 'anderson', 'and', 'denise', \"richard's\", 'characters', 'a', 'little.even', 'though', 'this', 'movie', \"didn't\", 'get', 'any', 'laughs', 'from', 'me,', 'it', 'kept', 'my', 'attention.i', \"wouldn't\", 'say', 'to', 'completely', 'avoid', 'this', 'movie,', 'but', 'there', 'are', 'thousands', 'of', 'better', 'films', 'for', 'you', 'to', 'spend', 'your', 'time', 'and', 'money', 'on', 'than', 'blonde', 'and', 'blonder.'], 'label': 'neg'}\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_iterator.dataset.examples[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BUILD THE MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our three layers are an embedding layer, our RNN, and a linear layer. All layers have their parameters initialized to random values, unless explicitly specified.\n",
    "\n",
    "The embedding layer is used to transform our sparse one-hot vector (sparse as most of the elements are 0) into a dense embedding vector (dense as the dimensionality is a lot smaller and all the elements are real numbers). This embedding layer is simply a single fully connected layer. As well as reducing the dimensionality of the input to the RNN, there is the theory that words which have similar impact on the sentiment of the review are mapped close together in this dense vector space. For more information about word embeddings, see here.\n",
    "\n",
    "The RNN layer is our RNN which takes in our dense vector and the previous hidden state $h_{t-1}$, which it uses to calculate the next hidden state, $h_t$. (see below pic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "a bytes-like object is required, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj, include, exclude)\u001b[0m\n\u001b[0;32m    968\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    969\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 970\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    971\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\IPython\\core\\display.py\u001b[0m in \u001b[0;36m_repr_mimebundle_\u001b[1;34m(self, include, exclude)\u001b[0m\n\u001b[0;32m   1207\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1208\u001b[0m             \u001b[0mmimetype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mimetype\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1209\u001b[1;33m             \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetadata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data_and_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malways_both\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1210\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1211\u001b[0m                 \u001b[0mmetadata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mmimetype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\IPython\\core\\display.py\u001b[0m in \u001b[0;36m_data_and_metadata\u001b[1;34m(self, always_both)\u001b[0m\n\u001b[0;32m   1216\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_data_and_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malways_both\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1217\u001b[0m         \u001b[1;34m\"\"\"shortcut for returning metadata with shape information, if defined\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1218\u001b[1;33m         \u001b[0mb64_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb2a_base64\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ascii'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1219\u001b[0m         \u001b[0mmd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1220\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "a bytes-like object is required, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\IPython\\core\\display.py\u001b[0m in \u001b[0;36m_repr_png_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1233\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_repr_png_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1234\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membed\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FMT_PNG\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1235\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data_and_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1237\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_repr_jpeg_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\IPython\\core\\display.py\u001b[0m in \u001b[0;36m_data_and_metadata\u001b[1;34m(self, always_both)\u001b[0m\n\u001b[0;32m   1216\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_data_and_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malways_both\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1217\u001b[0m         \u001b[1;34m\"\"\"shortcut for returning metadata with shape information, if defined\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1218\u001b[1;33m         \u001b[0mb64_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb2a_base64\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ascii'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1219\u001b[0m         \u001b[0mmd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1220\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image('RNN.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the linear layer takes the final hidden state and feeds it through a fully connected layer, $f(h_T)$, transforming it to the correct output dimension.\n",
    "\n",
    "The forward method is called when we feed examples into our model.\n",
    "\n",
    "Each batch, text, is a tensor of size [sentence length, batch size]. That is a batch of sentences, each having each word converted into a one-hot vector.\n",
    "\n",
    "You may notice that this tensor should have another dimension due to the one-hot vectors, however PyTorch conveniently stores a one-hot vector as it's index value, i.e. the tensor representing a sentence is just a tensor of the indexes for each token in that sentence. The act of converting a list of tokens into a list of indexes is commonly called numericalizing.\n",
    "\n",
    "The input batch is then passed through the embedding layer to get embedded, which gives us a dense vector representation of our sentences. embedded is a tensor of size [sentence length, batch size, embedding dim].\n",
    "\n",
    "embedded is then fed into the RNN. In some frameworks you must feed the initial hidden state, $h_0$, into the RNN, however in PyTorch, if no initial hidden state is passed as an argument it defaults to a tensor of all zeros.\n",
    "\n",
    "The RNN returns 2 tensors, output of size [sentence length, batch size, hidden dim] and hidden of size [1, batch size, hidden dim]. output is the concatenation of the hidden state from every time step, whereas hidden is simply the final hidden state. We verify this using the assert statement. Note the squeeze method, which is used to remove a dimension of size 1.\n",
    "\n",
    "Finally, we feed the last hidden state, hidden, through the linear layer, fc, to produce a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's start building the model\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, embedding_dim, hidden_dim):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        #size of the input text ---> text = [sent len, batch size]\n",
    "        embedded = self.embedding(text)\n",
    "        #size of the output of the embedding layer ---> embedded = [sent len, batch size, emb dim]\n",
    "        output, hidden = self.rnn(embedded)\n",
    "        #output = [sent len, batch size, hidden dim]\n",
    "        #hidden = [1, batch size, hidden dim]\n",
    "        out = self.fc(hidden.squeeze(0))\n",
    "        \n",
    "        assert torch.equal(output[-1,:,:], hidden.squeeze(0))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create an instance of our RNN class.\n",
    "\n",
    "The input dimension is the dimension of the one-hot vectors, which is equal to the vocabulary size.\n",
    "\n",
    "The embedding dimension is the size of the dense word vectors. This is usually around 50-250 dimensions, but depends on the size of the vocabulary.\n",
    "\n",
    "The hidden dimension is the size of the hidden states. This is usually around 100-500 dimensions, but also depends on factors such as on the vocabulary size, the size of the dense vectors and the complexity of the task.\n",
    "\n",
    "The output dimension is usually the number of classes, however in the case of only 2 classes the output value is between 0 and 1 and thus can be 1-dimensional, i.e. a single scalar real number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (embedding): Embedding(25002, 100)\n",
      "  (rnn): RNN(100, 256)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 1\n",
    "\n",
    "model = RNN(input_dim = INPUT_DIM, output_dim = OUTPUT_DIM, embedding_dim = EMBEDDING_DIM, hidden_dim = HIDDEN_DIM).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN THE MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll set up the training and then train the model.\n",
    "\n",
    "First, we'll create an optimizer. This is the algorithm we use to update the parameters of the module. Here, we'll use stochastic gradient descent (SGD). The first argument is the parameters will be updated by the optimizer, the second is the learning rate, i.e. how much we'll change the parameters by when we do a parameter update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define our optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll define our loss function. In PyTorch this is commonly called a criterion.\n",
    "\n",
    "The loss function here is binary cross entropy with logits.\n",
    "\n",
    "Our model currently outputs an unbound real number. As our labels are either 0 or 1, we want to restrict the predictions to a number between 0 and 1. We do this using the sigmoid or logit functions.\n",
    "\n",
    "We then use this this bound scalar to calculate the loss using binary cross entropy.\n",
    "\n",
    "The BCEWithLogitsLoss criterion carries out both the sigmoid and the binary cross entropy steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define our loss function\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our criterion function calculates the loss, however we have to write our function to calculate the accuracy.\n",
    "\n",
    "This function first feeds the predictions through a sigmoid layer, squashing the values between 0 and 1, we then round them to the nearest integer. This rounds any value greater than 0.5 to 1 (a positive sentiment) and the rest to 0 (a negative sentiment).\n",
    "\n",
    "We then calculate how many rounded predictions equal the actual labels and average it across the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum()/len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model(batch.text).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions, batch.label)\n",
    "        \n",
    "        acc = binary_accuracy(predictions, batch.label)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluate is similar to train, with a few modifications as you don't want to update the parameters when evaluating.\n",
    "\n",
    "model.eval() puts the model in \"evaluation mode\", this turns off dropout and batch normalization. Again, we are not using them in this model, but it is good practice to include them.\n",
    "\n",
    "No gradients are calculated on PyTorch operations inside the with no_grad() block. This causes less memory to be used and speeds up computation.\n",
    "\n",
    "The rest of the function is the same as train, with the removal of optimizer.zero_grad(), loss.backward() and optimizer.step(), as we do not update the model's parameters when evaluating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            \n",
    "            predictions = model(batch.text).squeeze(1)\n",
    "            \n",
    "            loss = criterion(predictions, batch.label)\n",
    "            \n",
    "            acc = binary_accuracy(predictions, batch.label)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also create a function to tell us how long an epoch takes to compare training times between models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then train the model through multiple epochs, an epoch being a complete pass through all examples in the training and validation sets.\n",
    "\n",
    "At each epoch, if the validation loss is the best we have seen so far, we'll save the parameters of the model and then after training has finished we'll use that model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 56s\n",
      "\tTrain Loss: 0.697 | Train Acc: 50.41%\n",
      "\t Val. Loss: 0.697 |  Val. Acc: 49.81%\n",
      "Epoch: 02 | Epoch Time: 0m 55s\n",
      "\tTrain Loss: 0.695 | Train Acc: 50.42%\n",
      "\t Val. Loss: 0.699 |  Val. Acc: 50.41%\n",
      "Epoch: 03 | Epoch Time: 0m 59s\n",
      "\tTrain Loss: 0.697 | Train Acc: 50.01%\n",
      "\t Val. Loss: 0.704 |  Val. Acc: 49.54%\n",
      "Epoch: 04 | Epoch Time: 0m 55s\n",
      "\tTrain Loss: 0.697 | Train Acc: 49.22%\n",
      "\t Val. Loss: 0.699 |  Val. Acc: 50.72%\n",
      "Epoch: 05 | Epoch Time: 0m 56s\n",
      "\tTrain Loss: 0.696 | Train Acc: 50.23%\n",
      "\t Val. Loss: 0.705 |  Val. Acc: 48.99%\n",
      "Epoch: 06 | Epoch Time: 0m 55s\n",
      "\tTrain Loss: 0.695 | Train Acc: 50.12%\n",
      "\t Val. Loss: 0.703 |  Val. Acc: 50.95%\n",
      "Epoch: 07 | Epoch Time: 0m 56s\n",
      "\tTrain Loss: 0.695 | Train Acc: 50.39%\n",
      "\t Val. Loss: 0.697 |  Val. Acc: 50.55%\n",
      "Epoch: 08 | Epoch Time: 0m 58s\n",
      "\tTrain Loss: 0.697 | Train Acc: 49.61%\n",
      "\t Val. Loss: 0.704 |  Val. Acc: 50.45%\n",
      "Epoch: 09 | Epoch Time: 0m 56s\n",
      "\tTrain Loss: 0.696 | Train Acc: 49.58%\n",
      "\t Val. Loss: 0.705 |  Val. Acc: 50.56%\n",
      "Epoch: 10 | Epoch Time: 0m 56s\n",
      "\tTrain Loss: 0.696 | Train Acc: 50.14%\n",
      "\t Val. Loss: 0.699 |  Val. Acc: 50.85%\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model = model, iterator = train_iterator, optimizer = optimizer, criterion = criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the metric we actually care about, the test loss and accuracy, which we get from our parameters that gave us the best validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.699 | Test Acc: 49.87%\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('tut1-model.pt'))\n",
    "\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NEXT STEPS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next notebook, the improvements we will make are:\n",
    "\n",
    "1. Different optimizer\n",
    "2. Use pre-trained word embeddings\n",
    "3. Different RNN architecture\n",
    "4. Bidirectional RNN\n",
    "5. Multi-layer RNN\n",
    "6. Regularization\n",
    "\n",
    "This will allow us to achieve ~85% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
